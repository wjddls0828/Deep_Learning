{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning_rps",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGEqpQmA_WZ6"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bht6Z5Cbnm_"
      },
      "source": [
        "## Transfer Learning 을 통한 가위-바위-보 분류 데이터 셋 분류 성능 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhbHXd2ZI1t3"
      },
      "source": [
        "### Step 1. Input tensor 와 Target tensor 준비(훈련데이터)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axECPsnlb5lA"
      },
      "source": [
        "(1) 가위-바위-보 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpywvV4KMjIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed82fe3b-b597-4951-a051-337d7853537f"
      },
      "source": [
        "url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip'\n",
        "\n",
        "path_to_zip = keras.utils.get_file('rps.zip',\n",
        "                                   origin=url,\n",
        "                                   extract=True,\n",
        "                                   cache_dir='/content')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n",
            "200687616/200682221 [==============================] - 3s 0us/step\n",
            "200695808/200682221 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CFDzcUpM2wJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c7665b-dd08-4b05-9082-67830c8cf5eb"
      },
      "source": [
        "url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip'\n",
        "\n",
        "path_to_zip = keras.utils.get_file('rps_test.zip',\n",
        "                                   origin=url,\n",
        "                                   extract=True,\n",
        "                                   cache_dir='/content')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip\n",
            "29523968/29516758 [==============================] - 0s 0us/step\n",
            "29532160/29516758 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5iHfTAhb-SM"
      },
      "source": [
        "(2) ImageDataGenerator를 이용해 이미지 파일을 load 하기 위한 경로 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmGW7BsTNbRz"
      },
      "source": [
        "train_dir = '/content/datasets/rps'\n",
        "test_dir = '/content/datasets/rps-test-set'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJj4NG2ucAfU"
      },
      "source": [
        "(3) ImageDataGenerator 객체 생성  \n",
        "* 객체 생성 시 rescale 인자를 이용하여 텐서 내 원소의 범위를 [0 ~ 255] => [0 ~ 1] 로 ReScaling 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DT1tnXgMoo0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toobDJJUMslq"
      },
      "source": [
        "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsAYG-IhcgsL"
      },
      "source": [
        "* .flow_from_directory() 메서드를 이용하여 학습데이터와 검증데이터를 위한 DirectoryIterator 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWdw-5EKMywK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25f1428-3b85-4f45-9a36-c08a68ef7447"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        seed=7)\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical',\n",
        "        subset='validation',\n",
        "        seed=7)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2016 images belonging to 3 classes.\n",
            "Found 504 images belonging to 3 classes.\n",
            "Found 372 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stk917_Sci0V"
      },
      "source": [
        "### Step 2. VGG16을 Backbone 으로 하는 모델 디자인 및 학습 정보 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP8hv-ZCcnQx"
      },
      "source": [
        "(1) Pre-trained 된 VGG16 모델 객체 생성\n",
        "  * imagenet 데이터를 이용해 학습된 모델 객체 생성\n",
        "  * classification layer 제외"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsBdZgjQS_9m"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHsguOaF7CMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e636fa8e-53b8-4951-9ec4-bff5bd2ffb68"
      },
      "source": [
        "conve_base = VGG16(include_top=False,\n",
        "                   weights='imagenet',\n",
        "                   input_shape=(224, 224, 3))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiqnkRJZ2SHO",
        "outputId": "2ad82249-5de7-4f0b-cd32-8b23784b4184"
      },
      "source": [
        "conve_base.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18TfCRgEc_mb"
      },
      "source": [
        "(2) VGG16 Backbone 모델에 classification layer 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnwc5pXX3f8x"
      },
      "source": [
        "model = keras.Sequential()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe8HApyF8YEk"
      },
      "source": [
        "model.add(conve_base)\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(256, activation='relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_hBr1cJ4Hzd",
        "outputId": "bf40043a-37bc-4862-a7a2-b4eb1c468e53"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 21,138,243\n",
            "Trainable params: 21,138,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4g29WFrdQYm"
      },
      "source": [
        "(3) VGG16 Backbone 모델의 가중치 동결(학습대상 가중치에서 제외)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDhAapMbd8jW"
      },
      "source": [
        "* VGG16 Backbone 모델의 가중치 동결 및 동결 후 학습대상 파라미터 개수 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUnRXobd4aW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff14383-32be-4ccc-a2e1-2467280f1d58"
      },
      "source": [
        "len(model.trainable_weights)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Cxfyz78vCW"
      },
      "source": [
        "conve_base.trainable = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYorLNyE9do9",
        "outputId": "9d04ed04-7169-4fc6-c822-9878d830a689"
      },
      "source": [
        "len(model.trainable_weights)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnSLvQov9om0",
        "outputId": "1915efd9-be85-49b7-da21-4cc0c10ec6e5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 21,138,243\n",
            "Trainable params: 6,423,555\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p58Gw79MePBh"
      },
      "source": [
        "(4) 학습을 위한 설정 정보 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spdqys60-4x4"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D-ob5jkfmZe"
      },
      "source": [
        "### Step 3. 모델에 데이터 generator 연결 후 학습 \n",
        "  * model.fit() 이용하여 데이터 연결 및 학습시키기\n",
        "  * 학습 과정은 history 변수에 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIl1NAH2-8Js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe05f3ce-9a40-4679-95ad-ece989d7e799"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=len(train_generator),\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=len(validation_generator))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "101/101 [==============================] - 68s 336ms/step - loss: 0.2082 - accuracy: 0.9648 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "101/101 [==============================] - 27s 266ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "101/101 [==============================] - 27s 268ms/step - loss: 9.3590e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 1.5485e-04 - accuracy: 1.0000 - val_loss: 9.9714e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 3.6376e-05 - accuracy: 1.0000 - val_loss: 7.3093e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 9.2986e-06 - accuracy: 1.0000 - val_loss: 3.4259e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 2.5158e-06 - accuracy: 1.0000 - val_loss: 1.9388e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 1.1109e-06 - accuracy: 1.0000 - val_loss: 2.9134e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 5.5081e-07 - accuracy: 1.0000 - val_loss: 2.0653e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 3.8684e-07 - accuracy: 1.0000 - val_loss: 1.3178e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 2.4534e-07 - accuracy: 1.0000 - val_loss: 2.3276e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 1.8000e-07 - accuracy: 1.0000 - val_loss: 1.6070e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 1.4263e-07 - accuracy: 1.0000 - val_loss: 1.4021e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "101/101 [==============================] - 27s 268ms/step - loss: 1.1200e-07 - accuracy: 1.0000 - val_loss: 1.5673e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "101/101 [==============================] - 27s 268ms/step - loss: 9.1536e-08 - accuracy: 1.0000 - val_loss: 1.3088e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "101/101 [==============================] - 27s 268ms/step - loss: 7.6989e-08 - accuracy: 1.0000 - val_loss: 1.5572e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "101/101 [==============================] - 27s 268ms/step - loss: 6.4572e-08 - accuracy: 1.0000 - val_loss: 2.1830e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 5.6471e-08 - accuracy: 1.0000 - val_loss: 1.3157e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 5.1385e-08 - accuracy: 1.0000 - val_loss: 1.2071e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 4.6182e-08 - accuracy: 1.0000 - val_loss: 1.0336e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "101/101 [==============================] - 27s 268ms/step - loss: 4.1333e-08 - accuracy: 1.0000 - val_loss: 1.0045e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 3.6129e-08 - accuracy: 1.0000 - val_loss: 1.4696e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 3.4355e-08 - accuracy: 1.0000 - val_loss: 1.0493e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 3.1458e-08 - accuracy: 1.0000 - val_loss: 8.7458e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 2.8442e-08 - accuracy: 1.0000 - val_loss: 1.1174e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 2.6787e-08 - accuracy: 1.0000 - val_loss: 1.0652e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "101/101 [==============================] - 27s 268ms/step - loss: 2.4717e-08 - accuracy: 1.0000 - val_loss: 8.6140e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 2.2825e-08 - accuracy: 1.0000 - val_loss: 8.3101e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 2.2293e-08 - accuracy: 1.0000 - val_loss: 6.7248e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "101/101 [==============================] - 27s 269ms/step - loss: 2.0578e-08 - accuracy: 1.0000 - val_loss: 9.5075e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PS8aRYN_YJa"
      },
      "source": [
        "### Step 4. 테스트 데이터 셋을 통한 모델의 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQarZ9C3f64d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25538a33-b7ab-4def-8864-efefc5c7c700"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_generator)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 8s 437ms/step - loss: 0.1616 - accuracy: 0.9462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IzmcIwRAYzO"
      },
      "source": [
        "del model"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}