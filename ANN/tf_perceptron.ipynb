{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcf_uOaLmpTB",
        "outputId": "ec16292f-d6f3-4d74-890c-f61d88b03b25"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 파라미터 값(input 특성 개수, 퍼셉트론의 개수, 학습률) 설정\n",
        "input_dim = 2\n",
        "hidden_units = 1\n",
        "learning_rate =0.01\n",
        "\n",
        "# 가중치(input 특성 : 2/ 퍼셉트론 : 1)\n",
        "w = tf.Variable(tf.random.uniform(shape=(input_dim,hidden_units)))\n",
        "\n",
        "# 편향(퍼셉트론 : 1)\n",
        "b = tf.Variable(tf.zeros(shape=(hidden_units)))\n",
        "\n",
        "# 설계한 퍼셉트론 모델의 파라미터 확인(코드 제출시 주석 처리)\n",
        "#print('*******퍼셉트론 모델의 초기 가중치*******')\n",
        "#print(w)\n",
        "#print('\\n*******퍼셉트론 모델의 초기 편향*******')\n",
        "#print(b)\n",
        "\n",
        "# 퍼셉트론의 수학 모델 f(x*w + b) 구현\n",
        "def predict(input):\n",
        "  # x*w + b 연산 구현\n",
        "  x = tf.matmul(input,w)+b\n",
        "  # relu 활성화 함수 구현\n",
        "  x = tf.maximum(0,x)\n",
        "  return x\n",
        "\n",
        "# loss(mse)\n",
        "def mse_loss(labels, predictions):\n",
        "  # MSE(Mean Square Error) 연산 구현\n",
        "  loss = tf.reduce_mean(tf.square(labels-predictions))\n",
        "  return loss\n",
        "\n",
        "# train\n",
        "def train(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # 퍼셉트론 모델을 예측값을 계산\n",
        "    predictions = predict(inputs)\n",
        "    # 모델의 예측값과 정답간의 에러를 loss 을 이용해 계산\n",
        "    loss = mse_loss(labels,predictions)\n",
        "    # 모델의 파라미터(w, b)가 loss 값에 미치는 영향도를 미분(오차역전파)을 통해 계산\n",
        "    gradient_lw, gradient_lb = tape.gradient(loss, [w,b])\n",
        "  # 경사하강법을 수행하여 모델의 파라미터(w, b) 업데이트\n",
        "  w.assign(w-learning_rate*gradient_lw)\n",
        "  b.assign(b-learning_rate*gradient_lb)\n",
        "  return loss\n",
        "\n",
        "# 퍼셉트론 모델 학습을 위한 OR Gate 데이터 생성\n",
        "inputs = np.array([[0, 0],\n",
        "                   [0, 1],\n",
        "                   [1, 0],\n",
        "                   [1, 1]], dtype=np.float32)\n",
        "\n",
        "labels = np.array([0, 1, 1, 1], dtype=np.float32)\n",
        "\n",
        "# OR Gate 데이터를 차트로 확인(코드 제출시 주석 처리)\n",
        "#plt.scatter(inputs[:, 0], inputs[:, 1], c=labels[:])\n",
        "#plt.show()\n",
        "\n",
        "# train 함수를 반복적으로 실행하여 퍼셉트론 모델을 학습\n",
        "for epoch in range(100):\n",
        "  # input 데이터와 label 데이터를 한 건씩 추출하여 train 함수에 전달\n",
        "  for x, y in zip(inputs, labels):\n",
        "    loss =train([x],[y])\n",
        "  # 학습 중간에 loss 값의 변화 출력(코드 제출시 주석 처리)\n",
        "  #if (epoch+1)%10 == 0:\n",
        "  #  print(\"Epoch {}: loss={}\".format(epoch+1, float(loss)))\n",
        "\n",
        "# 학습된 모델에 input 데이터 입력하여 예측결과 계산\n",
        "predictions = predict(inputs)\n",
        "\n",
        "# 모델의 예측결과를 차트로 확인(코드 제출시 주석 처리)\n",
        "#plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:]> 0.5)\n",
        "#plt.show()\n",
        "\n",
        "print('*******모델의 예측 결과*******')\n",
        "print(predictions[:]> 0.5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******모델의 예측 결과*******\n",
            "tf.Tensor(\n",
            "[[False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]], shape=(4, 1), dtype=bool)\n"
          ]
        }
      ]
    }
  ]
}